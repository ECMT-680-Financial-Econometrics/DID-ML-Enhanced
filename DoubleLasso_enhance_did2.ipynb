{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q3J5d-Rnc4Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aXQq33HaTOM",
        "outputId": "36926f94-d660-4e2f-e802-4cdf7d9337cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed data with ratio in change in mw saved to final_processed_with_ratio_in_mw.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 读取Excel文件\n",
        "excel_path = '/content/StateMinimumWage_Changes.xlsx'  # Colab中的Excel文件路径\n",
        "df = pd.read_excel(excel_path)\n",
        "\n",
        "# 筛选出没有1997年数据的州\n",
        "states_without_1997 = df[~df['statename'].isin(df.loc[df['year'] == 1997, 'statename'])]['statename'].unique()\n",
        "df_filtered = df[df['statename'].isin(states_without_1997)]\n",
        "\n",
        "# 保存到CSV\n",
        "output_csv_path = 'filtered_data_from_excel.csv'  # Colab中的文件名\n",
        "df_filtered.to_csv(output_csv_path, index=False)\n",
        "\n",
        "# 补充1990到1995年的数据\n",
        "required_years = [1990, 1991, 1992, 1993, 1994, 1995, 1996]  # 包含1996\n",
        "processed_df = pd.DataFrame()\n",
        "\n",
        "for state in states_without_1997:\n",
        "    state_data = df_filtered[df_filtered['statename'] == state].copy()\n",
        "    for year in required_years:\n",
        "        if year not in state_data['year'].values:\n",
        "            new_row = {\n",
        "                'statefips': state_data.iloc[0]['statefips'] if not state_data.empty else 'NaN',\n",
        "                'statename': state,\n",
        "                'year': year,\n",
        "                'month': 1,  # 默认为1月\n",
        "                'day': 1,    # 默认为1号\n",
        "                'mw': 0,\n",
        "                'changeinmw': 0\n",
        "            }\n",
        "            state_data = pd.concat([state_data, pd.DataFrame([new_row])], ignore_index=True)\n",
        "    processed_df = pd.concat([processed_df, state_data], ignore_index=True)\n",
        "\n",
        "# 排序并删除重复行\n",
        "processed_df.sort_values(by=['statename', 'year'], inplace=True)\n",
        "processed_df.drop_duplicates(subset=['statename', 'year'], keep='first', inplace=True)\n",
        "\n",
        "# 计算changeinmw和changeinmw_ratio\n",
        "processed_df['changeinmw'] = processed_df.groupby('statename')['mw'].diff().fillna(0).clip(lower=0)\n",
        "processed_df['changeinmw_ratio'] = processed_df.groupby('statename')['changeinmw'].transform(lambda x: x / x.shift(1))\n",
        "processed_df['changeinmw_ratio'] = processed_df['changeinmw_ratio'].replace([float('inf'), -float('inf')], 0).fillna(0)\n",
        "\n",
        "# 保存到CSV\n",
        "final_output_csv_with_ratio_path = 'final_processed_with_ratio_in_mw.csv'\n",
        "processed_df.to_csv(final_output_csv_with_ratio_path, index=False)\n",
        "\n",
        "print(f\"Processed data with ratio in change in mw saved to {final_output_csv_with_ratio_path}\")\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "# 假设Arkansas州的数据已经按照你的要求处理好\n",
        "arkansas_template = pd.DataFrame({\n",
        "    'year': [1990, 1991, 1992, 1993, 1994, 1995],\n",
        "    'changeinmw': [0, 0, 0.35, 0.15, 0.1, 0]  # 假设值，实际值应该是你计算出来的\n",
        "})\n",
        "\n",
        "# 读取最终的州际数据集\n",
        "final_df = pd.read_csv('/mnt/data/final_processed_with_ratio_in_mw.csv')\n",
        "\n",
        "# 填充缺失年份\n",
        "filled_final_df = pd.DataFrame()\n",
        "years_to_fill = range(1990, 1996)\n",
        "for state in final_df['statename'].unique():\n",
        "    state_data = final_df[final_df['statename'] == state]\n",
        "    filled_years = state_data['year'].unique()\n",
        "    for year in years_to_fill:\n",
        "        if year not in filled_years:\n",
        "            missing_row = {\n",
        "                'statefips': state_data.iloc[0]['statefips'] if not state_data.empty else 'NaN',\n",
        "                'statename': state,\n",
        "                'year': year,\n",
        "                'changeinmw': 0  # 填充0\n",
        "            }\n",
        "            state_data = pd.concat([state_data, pd.DataFrame([missing_row])], ignore_index=True)\n",
        "    filled_final_df = pd.concat([filled_final_df, state_data], ignore_index=True)\n",
        "\n",
        "# 排序并重置索引\n",
        "filled_final_df.sort_values(by=['statename', 'year'], inplace=True)\n",
        "filled_final_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# 进行双重Lasso回归以找到与Arkansas州最匹配的州\n",
        "# 注意：下面的代码块是伪代码，因为双重Lasso需要特定的统计库实现，我在这里提供一个概念性框架\n",
        "best_state = None\n",
        "best_score = float('-inf')\n",
        "\n",
        "for state in filled_final_df['statename'].unique():\n",
        "    if state != 'Arkansas':\n",
        "        state_data = filled_final_df[filled_final_df['statename'] == state]\n",
        "        # 确保对比的年份一致\n",
        "        state_data = state_data[state_data['year'].isin(arkansas_template['year'])]\n",
        "        X = state_data[['year', 'changeinmw']].values\n",
        "        y = arkansas_template['changeinmw'].values\n",
        "        # 使用交叉验证的Lasso回归\n",
        "        lasso = LassoCV(cv=5).fit(X, y)\n",
        "        score = lasso.score(X, y)\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_state = state\n",
        "\n",
        "print(f\"The state most similar to Arkansas based on changeinmw is: {best_state}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CFVIA5jRdfbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf731d5-72be-4359-fcd3-868b5ff28ef5",
        "id": "hkvUcQ1wdf4D"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The state most similar to Arkansas based on changeinmw is: New York\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "# 假设Arkansas州的数据已经按照你的要求处理好\n",
        "arkansas_template = pd.DataFrame({\n",
        "    'year': [1990, 1991, 1992, 1993, 1994, 1995],\n",
        "    'changeinmw': [0, 0, 0.35, 0.15, 0.1, 0]  # 假设值，实际值应该是你计算出来的\n",
        "})\n",
        "\n",
        "# 读取最终的州际数据集\n",
        "final_df = pd.read_csv('/content/final_processed_with_ratio_in_mw.csv')\n",
        "\n",
        "# 填充缺失年份\n",
        "filled_final_df = pd.DataFrame()\n",
        "years_to_fill = range(1990, 1996)\n",
        "for state in final_df['statename'].unique():\n",
        "    state_data = final_df[final_df['statename'] == state]\n",
        "    filled_years = state_data['year'].unique()\n",
        "    for year in years_to_fill:\n",
        "        if year not in filled_years:\n",
        "            missing_row = {\n",
        "                'statefips': state_data.iloc[0]['statefips'] if not state_data.empty else 'NaN',\n",
        "                'statename': state,\n",
        "                'year': year,\n",
        "                'changeinmw': 0  # 填充0\n",
        "            }\n",
        "            state_data = pd.concat([state_data, pd.DataFrame([missing_row])], ignore_index=True)\n",
        "    filled_final_df = pd.concat([filled_final_df, state_data], ignore_index=True)\n",
        "\n",
        "# 排序并重置索引\n",
        "filled_final_df.sort_values(by=['statename', 'year'], inplace=True)\n",
        "filled_final_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# 进行双重Lasso回归以找到与Arkansas州最匹配的州\n",
        "# 注意：下面的代码块是伪代码，因为双重Lasso需要特定的统计库实现，我在这里提供一个概念性框架\n",
        "best_state = None\n",
        "best_score = float('-inf')\n",
        "\n",
        "for state in filled_final_df['statename'].unique():\n",
        "    if state != 'Arkansas':\n",
        "        state_data = filled_final_df[filled_final_df['statename'] == state]\n",
        "        # 确保对比的年份一致\n",
        "        state_data = state_data[state_data['year'].isin(arkansas_template['year'])]\n",
        "        X = state_data[['year', 'changeinmw']].values\n",
        "        y = arkansas_template['changeinmw'].values\n",
        "        # 使用交叉验证的Lasso回归\n",
        "        lasso = LassoCV(cv=5).fit(X, y)\n",
        "        score = lasso.score(X, y)\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_state = state\n",
        "\n",
        "print(f\"The state most similar to Arkansas based on changeinmw is: {best_state}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.formula.api as smf\n",
        "#DID Without machine learning enhance\n",
        "# Load the data\n",
        "df = pd.read_csv(r\"/content/data_93-03.csv\")\n",
        "\n",
        "# Select data for Arkansas State\n",
        "df_ar = df[df['statenum'] == 5].copy()\n",
        "\n",
        "# Determine the first year of minimum wage change for Arkansas\n",
        "first_policy_change_year = 1993\n",
        "\n",
        "# Create a 'Post' variable for the years after the first policy change\n",
        "df_ar['Post'] = (df_ar['year'] >= first_policy_change_year).astype(int)\n",
        "\n",
        "# Since we're only interested in the effect after the first change,\n",
        "# we need to create a 'Treat' variable that identifies the policy change\n",
        "# For simplification, we'll consider a change in the minimum wage ('MW') as treatment\n",
        "df_ar['Treat'] = (df_ar['year'] == first_policy_change_year) & (df_ar['MW'].diff() != 0).astype(int)\n",
        "\n",
        "# Create the interaction term for the treatment effect after the policy change\n",
        "df_ar['Post*Treat'] = df_ar['Post'] * df_ar['Treat']\n",
        "\n",
        "# Define the regression formula, no state fixed effects are included since we are only analyzing Arkansas\n",
        "# Year fixed effects are included to control for any time-specific effects\n",
        "formula = 'emp_rate ~ Post*Treat + C(year)'\n",
        "\n",
        "# Fit the DiD model\n",
        "result_ar = smf.ols(formula, data=df_ar).fit()\n",
        "\n",
        "# Print the regression results\n",
        "print(result_ar.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRVlUf18s9ec",
        "outputId": "4ff49f08-5267-478b-e171-0b97738ae586"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:               emp_rate   R-squared:                       0.778\n",
            "Model:                            OLS   Adj. R-squared:                  0.777\n",
            "Method:                 Least Squares   F-statistic:                     1636.\n",
            "Date:                Wed, 24 Apr 2024   Prob (F-statistic):               0.00\n",
            "Time:                        06:04:07   Log-Likelihood:                 12269.\n",
            "No. Observations:                5148   AIC:                        -2.451e+04\n",
            "Df Residuals:                    5136   BIC:                        -2.444e+04\n",
            "Df Model:                          11                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "======================================================================================\n",
            "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------------\n",
            "Intercept              0.2200      0.001    425.569      0.000       0.219       0.221\n",
            "Treat[T.True]         -0.0235      0.011     -2.102      0.036      -0.045      -0.002\n",
            "C(year)[T.1994]        0.0636      0.001     43.480      0.000       0.061       0.066\n",
            "C(year)[T.1995]        0.0332      0.001     22.717      0.000       0.030       0.036\n",
            "C(year)[T.1996]       -0.0213      0.001    -14.545      0.000      -0.024      -0.018\n",
            "C(year)[T.1997]       -0.0300      0.001    -20.504      0.000      -0.033      -0.027\n",
            "C(year)[T.1998]       -0.0392      0.001    -26.808      0.000      -0.042      -0.036\n",
            "C(year)[T.1999]       -0.0390      0.001    -26.692      0.000      -0.042      -0.036\n",
            "C(year)[T.2000]       -0.0556      0.001    -38.030      0.000      -0.058      -0.053\n",
            "C(year)[T.2001]       -0.0708      0.001    -48.471      0.000      -0.074      -0.068\n",
            "C(year)[T.2002]       -0.0668      0.001    -45.684      0.000      -0.070      -0.064\n",
            "C(year)[T.2003]       -0.0716      0.001    -48.999      0.000      -0.074      -0.069\n",
            "Post                   0.2200      0.001    425.569      0.000       0.219       0.221\n",
            "Post:Treat[T.True]    -0.0235      0.011     -2.102      0.036      -0.045      -0.002\n",
            "==============================================================================\n",
            "Omnibus:                      512.235   Durbin-Watson:                   2.401\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              802.718\n",
            "Skew:                          -0.733   Prob(JB):                    4.92e-175\n",
            "Kurtosis:                       4.263   Cond. No.                     4.10e+17\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 6.37e-32. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "#Machine learning enhanced results\n",
        "# Load the dataset\n",
        "df = pd.read_csv(r\"/content/data_93-03.csv\")\n",
        "\n",
        "# Identify Arkansas as the treatment group (5) and New York as the control group (36)\n",
        "df['Treat'] = (df['statenum'] == 5).astype(int)\n",
        "df['Control'] = (df['statenum'] == 36).astype(int)\n",
        "\n",
        "# Since we're focusing on a multi-period DiD, we should create a post-treatment indicator\n",
        "# for each year after the first policy change in Arkansas. This example assumes that the\n",
        "\n",
        "# Find the years of policy changes in Arkansas\n",
        "policy_change_years = df[df['statenum'] == 5]['year'].unique()\n",
        "policy_change_years.sort()\n",
        "\n",
        "# Remove years before the first policy change\n",
        "policy_change_years = policy_change_years[policy_change_years >= 1993]\n",
        "\n",
        "# Create a column for each post-treatment year\n",
        "for year in policy_change_years:\n",
        "  # Create a post-treatment indicator for this year\n",
        "  df[f'Post_{year}'] = (df['year'] >= year).astype(int)\n",
        "\n",
        "# We'll create an interaction term for the treatment group and each post-treatment year\n",
        "for year in policy_change_years:\n",
        "  df[f'Interaction_{year}'] = df[f'Post_{year}'] * df['Treat']\n",
        "\n",
        "# Construct the formula for our DiD model, including the interaction terms and year fixed effects\n",
        "interaction_terms = [f'Interaction_{year}' for year in policy_change_years]\n",
        "formula = 'emp_rate ~ ' + ' + '.join(interaction_terms) + ' + C(year)'\n",
        "\n",
        "# We restrict our dataset to the control and treatment groups\n",
        "did_df = df[(df['Treat'] == 1) | (df['Control'] == 1)]\n",
        "\n",
        "# Fit the DiD model using ordinary least squares (OLS)\n",
        "model = smf.ols(formula, data=did_df).fit()\n",
        "\n",
        "# Output the results\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTH2kFG4rTJ6",
        "outputId": "85c1a1f7-c647-4f08-c809-9bae1f266b99"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:               emp_rate   R-squared:                       0.884\n",
            "Model:                            OLS   Adj. R-squared:                  0.884\n",
            "Method:                 Least Squares   F-statistic:                     3734.\n",
            "Date:                Wed, 24 Apr 2024   Prob (F-statistic):               0.00\n",
            "Time:                        05:58:32   Log-Likelihood:                 24268.\n",
            "No. Observations:               10296   AIC:                        -4.849e+04\n",
            "Df Residuals:                   10274   BIC:                        -4.833e+04\n",
            "Df Model:                          21                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "====================================================================================\n",
            "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------\n",
            "Intercept            0.3753      0.001    353.886      0.000       0.373       0.377\n",
            "C(year)[T.1994]      0.1164      0.001     77.600      0.000       0.113       0.119\n",
            "C(year)[T.1995]      0.0623      0.001     41.511      0.000       0.059       0.065\n",
            "C(year)[T.1996]     -0.0428      0.001    -28.510      0.000      -0.046      -0.040\n",
            "C(year)[T.1997]     -0.0449      0.001    -29.921      0.000      -0.048      -0.042\n",
            "C(year)[T.1998]     -0.0486      0.001    -32.432      0.000      -0.052      -0.046\n",
            "C(year)[T.1999]     -0.0627      0.001    -41.778      0.000      -0.066      -0.060\n",
            "C(year)[T.2000]     -0.0610      0.001    -40.674      0.000      -0.064      -0.058\n",
            "C(year)[T.2001]     -0.0879      0.001    -58.622      0.000      -0.091      -0.085\n",
            "C(year)[T.2002]     -0.0801      0.001    -53.395      0.000      -0.083      -0.077\n",
            "C(year)[T.2003]     -0.0903      0.001    -60.237      0.000      -0.093      -0.087\n",
            "Interaction_1993     0.0647      0.001     43.149      0.000       0.062       0.068\n",
            "Interaction_1994    -0.0527      0.002    -24.858      0.000      -0.057      -0.049\n",
            "Interaction_1995     0.0238      0.002     11.209      0.000       0.020       0.028\n",
            "Interaction_1996     0.0505      0.002     23.832      0.000       0.046       0.055\n",
            "Interaction_1997    -0.0066      0.002     -3.109      0.002      -0.011      -0.002\n",
            "Interaction_1998    -0.0054      0.002     -2.569      0.010      -0.010      -0.001\n",
            "Interaction_1999     0.0142      0.002      6.689      0.000       0.010       0.018\n",
            "Interaction_2000    -0.0182      0.002     -8.595      0.000      -0.022      -0.014\n",
            "Interaction_2001     0.0117      0.002      5.495      0.000       0.007       0.016\n",
            "Interaction_2002    -0.0038      0.002     -1.775      0.076      -0.008       0.000\n",
            "Interaction_2003     0.0054      0.002      2.553      0.011       0.001       0.010\n",
            "==============================================================================\n",
            "Omnibus:                     3885.425   Durbin-Watson:                   2.227\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            29887.994\n",
            "Skew:                          -1.610   Prob(JB):                         0.00\n",
            "Kurtosis:                      10.700   Cond. No.                         31.1\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    }
  ]
}