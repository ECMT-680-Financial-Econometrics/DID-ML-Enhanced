{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    %Aw   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     10.89\n",
      "Date:                Sun, 28 Apr 2024   Prob (F-statistic):           0.000966\n",
      "Time:                        00:59:53   Log-Likelihood:            -2.1911e+06\n",
      "No. Observations:              381888   AIC:                         4.382e+06\n",
      "Df Residuals:                  381886   BIC:                         4.382e+06\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const           -1.3853      0.455     -3.047      0.002      -2.277      -0.494\n",
      "BHcountpcall     3.4043      1.032      3.300      0.001       1.382       5.426\n",
      "==============================================================================\n",
      "Omnibus:                  1971058.660   Durbin-Watson:                   1.698\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):   68315390805285.211\n",
      "Skew:                        -242.087   Prob(JB):                         0.00\n",
      "Kurtosis:                   65524.682   Cond. No.                         10.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"D:\\desktop\\24spring\\ECMT680\\midterm2\\replicate\\ethnic DiD\\changew9303thrid.csv\")  # Please replace with your file path\n",
    "\n",
    "# Drop any potential missing values\n",
    "df = df.dropna(subset=['%Aw', 'BHcountpcall'])\n",
    "\n",
    "# Define the dependent and independent variables for the model\n",
    "X = df['BHcountpcall']  # Independent variable\n",
    "Y = df['%Aw']  # Dependent variable\n",
    "\n",
    "# Add a constant term (intercept) to the independent variable\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Build and fit the model\n",
    "model = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: 205.8930003049887 +/- 252.5383668247715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Data Preparation\n",
    "# Assume df is a clean dataset, and all columns are numeric\n",
    "X = df.drop(['BHcountpcall', '%Aw'], axis=1)  # Independent variable set\n",
    "y = df['%Aw']  # Dependent variable\n",
    "\n",
    "# Create a Random Forest Regressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Run cross-validation to evaluate the model\n",
    "scores = cross_val_score(rf, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Print the mean and standard deviation of cross-validation results\n",
    "print(f\"Cross-validated scores: {-np.mean(scores)} +/- {np.std(scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: statenum, Importance: 0.003338514202213341\n",
      "Feature: year, Importance: 9.89105855920656e-07\n",
      "Feature: avewage, Importance: 0.8948289323394237\n",
      "Feature: countall, Importance: 0.012031915767105782\n",
      "Feature: MW, Importance: 0.0070072565830962665\n",
      "Feature: DMW, Importance: 1.2064729271456811e-06\n",
      "Feature: w, Importance: 0.01010660096823677\n",
      "Feature: Aw, Importance: 0.072684584561141\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest Regressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model on the training set\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the feature importances\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Print the importance of each feature\n",
    "for feature, importance in zip(X.columns, feature_importances):\n",
    "    print(f\"Feature: {feature}, Importance: {importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen alpha: 0.0005036599446830284\n",
      "Coefficients: [0.50304711]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"D:\\desktop\\24spring\\ECMT680\\midterm2\\replicate\\ethnic DiD\\changew9303thrid.csv\")  # Please replace with your file path\n",
    "\n",
    "# Drop any potential missing values\n",
    "df = df.dropna(subset=['%Aw', 'BHcountpcall'])\n",
    "\n",
    "# Define the dependent and independent variables for the model\n",
    "X = df[['BHcountpcall']]  # Ensure X is a DataFrame rather than a Series\n",
    "Y = df['%Aw']\n",
    "\n",
    "# Data standardization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use cross-validation to find the optimal alpha value\n",
    "lasso = LassoCV(cv=5, random_state=0).fit(X_train, y_train)\n",
    "\n",
    "# View the chosen alpha value and corresponding coefficients\n",
    "print(f'Chosen alpha: {lasso.alpha_}')\n",
    "print(f'Coefficients: {lasso.coef_}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
